{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project is about analyzing app data from Google Play and Apple App stores. We'll pretend we're data analysts working for a company building Android and iOS apps. Our company only build apps that are free, and revenue comes from in-app ads. \n",
    "\n",
    "The goal is to use Python and Jupyter Notebook to profile the most profitable apps on the Google Play and Apple App stores Going through the data will help our developers understand what types of apps users gravitate towards.\n",
    "\n",
    "The data for [Google Play][1] and [Apple App Store][2] can be downloaded at Kaggle.\n",
    "\n",
    "[1]:https://www.kaggle.com/lava18/google-play-store-apps\n",
    "[2]:https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring the Data\n",
    "\n",
    "First we open the files and give them corresponding variable names. The header column is separated from the data for quick access. Here we will use the `explore_data()` function for exploration. It prints the rows in the list so they're readable, and finds the number of rows and columns if `rows_and_columns` is `True`. It assumes the input dataset doesn't have a header row.\n",
    "\n",
    "The first few rows of each data set are printed along with the number of rows and columns. We also try and identify some columns that could help with our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "#Open .csv files\n",
    "file1 = open(\"AppleStore.csv\", encoding='utf8')\n",
    "file2 = open(\"googleplaystore.csv\", encoding='utf8')\n",
    "\n",
    "apple_file = reader(file1)\n",
    "apple_apps_data = list(apple_file) #lists of list\n",
    "\n",
    "google_file = reader(file2)\n",
    "google_apps_data = list(google_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the header from the data set \n",
    "apple_head = apple_apps_data[0]\n",
    "apple_data = apple_apps_data[1:]\n",
    "\n",
    "google_head = google_apps_data[0]\n",
    "google_data = google_apps_data[1:]\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # new empty line for separation\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows:\", len(dataset))\n",
    "        print(\"Number of columns:\", len(dataset[0]))\n",
    "\n",
    "#First few rows\n",
    "print(\"Apple Rows\")\n",
    "explore_data(apple_data, 1, 3, True)\n",
    "print('\\n')\n",
    "print(\"Google Rows\")\n",
    "explore_data(google_data, 1, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring Columns\n",
    "print(apple_head, '\\n')\n",
    "print(google_head, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns we could use need to be related to price (we develop free apps only) and the user ratings for the app. They're detailed in two tables here:\n",
    "\n",
    "| Google Column Name | Description |\n",
    "|:-----------:|:------------:|\n",
    "| 'Rating' | User rating of the app |\n",
    "| 'Installs' | Number of downloads |\n",
    "| 'Price' | Price of the App |\n",
    "| 'Type' | Whether an app is paid or free |\n",
    "\n",
    "| Apple Column Name | Description |\n",
    "|:---------:|:---------:|\n",
    "| 'user_rating' | Average user rating (for all version) |\n",
    "| 'user_rating_ver' | Average user rating (for current version) |\n",
    "| 'Price' | Price of the app |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong Data\n",
    "\n",
    "The discussion section for the Google Play Store data set describes an error for row 10472 (data set without the header). Printing row 10472, the header, and another row show the rating for row 10472 has a rating of 19, which is incorrect, since the maximum rating is 5. Therefore we'll delete this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(google_head, '\\n') #header\n",
    "print(google_data[10472], '\\n') # incorrect\n",
    "print(google_data[10473]) #correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del google_data[10472] # Running this more than once will delete more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Apps\n",
    "### Part One\n",
    "\n",
    "From the discussion section for the Google Play Store data, duplicate entries for the same applications have been found. An example is Instagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in google_data:\n",
    "    name = app[0]\n",
    "    if name == 'Instagram':\n",
    "        print(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a `for` loop we see that there's 1,181 duplicate apps. In this case, getting rid of the duplicate app data will make our analysis more accurate. The duplicates won't be removed randomly. Take the Instagram app duplicates. All the data in each row is the same except for the 4th entry, which the number of user reviews. The different amount of user reviews suggests the data was taken at different times. It seems the higher the number of reviews, the more recent the data is. As such, we will keep the row with the highest amount of user reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = []\n",
    "unique = []\n",
    "\n",
    "for app in google_data:\n",
    "    app_name = app[0]\n",
    "    if app_name in unique:\n",
    "        duplicate.append(app_name)\n",
    "    else:\n",
    "        unique.append(app_name)\n",
    "\n",
    "print('Number of duplicate apps:', len(duplicate))\n",
    "print('\\n')\n",
    "print('Examples of duplicate apps:', duplicate[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the duplicate Google Play Store apps we should be left with 9659 unique apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length after duplicates:', len(google_data) - 1181)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the duplicates, we'll create a dictionary where each key is a unqiue app name and the corresponding dictionary value is the highest number of reviews for that particular app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {} #empty dictionary\n",
    "for app in google_data:\n",
    "    name = app[0] #app name\n",
    "    n_reviews = float(app[3]) #number of reviews for the app\n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        '''\n",
    "        if an app name is in the dictionary and the number of its\n",
    "        reviews is less than the duplicate's app number of reviews, update\n",
    "        the number of reviews for that app.\n",
    "        '''\n",
    "        reviews_max[name] += n_reviews\n",
    "    if name not in reviews_max:\n",
    "        # if app not in dictionary, create a new key with reviews as the value\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "len(reviews_max) # is 9659 as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the `reviews_max`dictionary to remove the duplicate rows. The list `android_clean` will hold a list of lists of our cleaned data while the `already_added` list helps us keep track of already added apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = [] #list for new cleaned data set\n",
    "already_added = [] #app names\n",
    "\n",
    "for app in google_data:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        '''\n",
    "        If the number of reviews is equal to the reviews in reviews_name,\n",
    "        and the app is not in already_added, add the entire row to\n",
    "        android_clean, and append the name of the app to already_added.\n",
    "        '''\n",
    "        android_clean.append(app)\n",
    "        already_added.append(name) \n",
    "        #this second condition is for duplicate apps that have the same number of reviews\n",
    "\n",
    "print('Expected:', len(google_data) - 1181)\n",
    "len(android_clean) #should be 9659"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
